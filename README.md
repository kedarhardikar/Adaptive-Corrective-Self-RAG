ğŸ” Adaptive-Corrective-Self-RAG (LangGraph-Powered)
A modular, multi-stage Retrieval-Augmented Generation (RAG) pipeline built using LangGraph. This project introduces adaptive routing, hallucination grading, and automated self-correction, enabling robust and reliable question answering over vector-based and web data sources.

ğŸš€ Features
âœ… LangGraph Workflow with conditional and looping logic

ğŸ“„ RAG Node powered by vector search and LLM generation

ğŸŒ Web Search Node as fallback when internal docs are insufficient

ğŸ§  LLM-based Graders for:

Relevance of retrieved chunks

Hallucination detection

Answer usefulness

ğŸ”„ Retry Loops for hallucinated generations

ğŸ§ª Unit Tested grading logic with pytest

ğŸ§  Architecture
graph TD;
    Start --> Router
    Router -->|vectorstore| Retrieve
    Router -->|websearch| WebSearch
    Retrieve --> GradeDocs
    GradeDocs -->|relevant| Generate
    GradeDocs -->|not relevant| WebSearch
    WebSearch --> Generate
    Generate --> GradeAnswer
    GradeAnswer -->|useful| End
    GradeAnswer -->|not useful| WebSearch
    GradeAnswer -->|hallucinated| Generate

ğŸ“ Project Structure
Advanced_RAG/
â”œâ”€â”€ main.py                      # Entry point to run the workflow
â”œâ”€â”€ ingestion.py                 # Vector DB creation & retriever object
â”œâ”€â”€ .env                         # API keys (GROQ_API_KEY)
â”œâ”€â”€ .gitignore                   # Ignores .env, __pycache__, etc.

graph/
â”œâ”€â”€ graph1.py                    # Builds and compiles LangGraph workflow
â”œâ”€â”€ consts.py                    # Constants like RETRIEVE, GENERATE
â”œâ”€â”€ state.py                     # Defines the GraphState TypedDict

graph/nodes/                     # LangGraph nodes
â”œâ”€â”€ retrieve.py                  # Retrieves documents from vector store
â”œâ”€â”€ generate.py                  # Generates answer using LLM
â”œâ”€â”€ grader.py                    # Grades doc relevance
â”œâ”€â”€ web_search.py                # Tool for external search

graph/chains/                    # LangChain Runnables and chains
â”œâ”€â”€ generation.py                # Prompt + LLM + parser
â”œâ”€â”€ answer_grader.py             # Grades if answer addresses question
â”œâ”€â”€ hallucination_grader.py      # Checks grounding in context
â”œâ”€â”€ router.py                    # Classifies query source (web vs vector)
â”œâ”€â”€ tests/test_chains.py         # Unit tests for grading logic


ğŸ§° Tech Stack
LangGraph
LangChain
ChatGroq
Python 3.10+
ChromaDB
dotenv
Pytest

âš™ï¸ Setup & Installation

1. Clone the repo
git clone https://github.com/kedarhardikar/Adaptive-Corrective-Self-RAG.git
cd Adaptive-Corrective-Self-RAG

2. Create and activate virtual env

3. Create .env file
   GROQ_API_KEY 
   LANGSMITH_TRACING=true #optional
   LANGSMITH_ENDPOINT="https://api.smith.langchain.com" #optional
   LANGSMITH_API_KEY  #optional
   TAVILY_API_KEY 

4. Ingest documents
   python ingestion.py

5. Run the agent
   python run main.py


âœï¸ Prompting Strategy
Uses RAG prompt from LangChain Hub: rlm/rag-prompt
Uses with_structured_output() for grading chains (true/false logic)
Chain outputs are deterministic (temperature=0)
