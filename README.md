# ğŸ” Adaptive-Corrective-Self-RAG (LangGraph-Powered)

A modular, multi-stage Retrieval-Augmented Generation (RAG) pipeline built using **LangGraph**.  
This project introduces **adaptive routing**, **hallucination grading**, and **automated self-correction**, enabling robust and reliable question answering over vector-based and web data sources.

---

## ğŸš€ Features

- âœ… **LangGraph Workflow** with conditional and looping logic  
- ğŸ“„ **RAG Node** powered by vector search and LLM generation  
- ğŸŒ **Web Search Node** as fallback when internal docs are insufficient  
- ğŸ§  **LLM-based Graders** for:  
  - Relevance of retrieved chunks  
  - Hallucination detection  
  - Answer usefulness  
- ğŸ”„ **Retry Loops** for hallucinated generations  
- ğŸ§ª **Unit Tested** grading logic using `pytest`  

---

## ğŸ§  Architecture

```mermaid
graph TD;
  Start --> Router
  Router -->|vectorstore| Retrieve
  Router -->|websearch| WebSearch
  Retrieve --> GradeDocs
  GradeDocs -->|relevant| Generate
  GradeDocs -->|not relevant| WebSearch
  WebSearch --> Generate
  Generate --> GradeAnswer
  GradeAnswer -->|useful| End
  GradeAnswer -->|not useful| WebSearch
  GradeAnswer -->|hallucinated| Generate
